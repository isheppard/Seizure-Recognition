{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference link (PYEEG)\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070217/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import glob\n",
    "import numpy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_patient_data(paths):\n",
    "\n",
    "\n",
    "    # Load training data for patient\n",
    "    if \"train\" in paths:\n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        print('...loading train data')\n",
    "        start = time.time()\n",
    "\n",
    "        for path in sorted(glob.glob(paths), key=numericalSort):\n",
    "            X.append(sio.loadmat(path))\n",
    "            Y.append(int(path[-5]))\n",
    "\n",
    "        Y = numpy.array(Y)\n",
    "        print('time elapsed: %s sec' %(time.time() - start))\n",
    "\n",
    "        return(X, Y)\n",
    "    \n",
    "    # Load test data for patient\n",
    "    else:\n",
    "        \n",
    "\n",
    "        X = []\n",
    "        file_array = []\n",
    "\n",
    "        print('...loading test data')\n",
    "        start = time.time()\n",
    "\n",
    "        for path in sorted(glob.glob(paths), key=numericalSort):\n",
    "            X.append(sio.loadmat(path))\n",
    "            file_array.append(os.path.split(path)[1])\n",
    "\n",
    "        print('time elapsed: %s sec' %(time.time() - start))\n",
    "\n",
    "        return(X, file_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The numericalSort function splits out any digits in a filename, \n",
    "# turns it into an actual number, and returns the result for sorting\n",
    "\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find samples of training set X that contain no data, or consist entirely of zeros\n",
    "def find_zero_index(X):\n",
    "    zero_index = []\n",
    "    print('...locating zero-data')\n",
    "    \n",
    "    for i in xrange(len(X)):\n",
    "        if numpy.sum(numpy.absolute(X[i]['dataStruct']['data'][0][0])) == 0:\n",
    "            zero_index.append(i)\n",
    "    \n",
    "    print('length of zero-data: ' + str(len(zero_index)))\n",
    "    return zero_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all-zero data\n",
    "# X must be list, Y can be numpy array which is cast to a list, and cast back to numpy array upon return\n",
    "def remove_zero_data(X, Y):\n",
    "    \n",
    "    zero_index = find_zero_index(X)\n",
    "    index_correction = 0\n",
    "    # index_correction is needed because every time element is deleted from a list the following elements are shifted\n",
    "    # EX: if 2nd element is deleted, the 3rd element becomes the 2nd, the 4th becomes the 3rd, etc.\n",
    "    Y = list(Y)\n",
    "    print('...removing zero-data')\n",
    "    \n",
    "    for i in xrange(len(zero_index)):\n",
    "\n",
    "        del X[zero_index[i] - index_correction]\n",
    "        del Y[zero_index[i] - index_correction]\n",
    "\n",
    "        index_correction += 1\n",
    "   \n",
    "    Y = numpy.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def n_sample_gradient(X):\n",
    "    \n",
    "    \n",
    "    num_freq= X.shape[1]\n",
    "    channels = X.shape[2]\n",
    "    samples = X.shape[0]\n",
    "    \n",
    "    grad_X = numpy.zeros([samples, num_freq, channels])\n",
    "        \n",
    "    for sample in xrange(X.shape[0]):\n",
    "         for channel in xrange(X.shape[2]):\n",
    "            grad_X[sample, :, channel] = numpy.gradient(X[sample,:,channel])\n",
    "            \n",
    "    return grad_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hjorth_mobility(X):\n",
    "    \n",
    "    grad_X = n_sample_gradient(X)\n",
    "    var_X = numpy.zeros([X.shape[0], \n",
    "                         X.shape[2] ])\n",
    "    grad_var_X = numpy.zeros([X.shape[0], \n",
    "                              X.shape[2]])\n",
    "\n",
    "    \n",
    "    for sample in xrange(X.shape[0]):\n",
    "        var_X[sample, :] = numpy.var(X[sample,:,:], axis=0)\n",
    "        grad_var_X[sample, :] = numpy.var(grad_X[sample, :, :], axis=0)\n",
    "\n",
    "    \n",
    "    mobility = numpy.sqrt(grad_var_X/var_X)\n",
    "    \n",
    "    \n",
    "    return mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hjorth_complexity(X):\n",
    "    \n",
    "    grad_X = n_sample_gradient(X)\n",
    "            \n",
    "    mobility = hjorth_mobility(X)\n",
    "    mobility_dxdt = hjorth_mobility(grad_X)\n",
    "    \n",
    "    complexity = mobility_dxdt/mobility\n",
    "    \n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_X_batch(X, samples, index):\n",
    "    X_batch = numpy.zeros([samples, \n",
    "                          X[0]['dataStruct']['data'][0][0].shape[0],\n",
    "                          X[0]['dataStruct']['data'][0][0].shape[1]])\n",
    "    \n",
    "    for sample in xrange(samples):\n",
    "        X_batch[sample,:,:] = X[sample]['dataStruct']['data'][0][0]\n",
    "        \n",
    "    return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hjorth_activity(X):\n",
    "\n",
    "    activity = numpy.zeros([len(X), X[0]['dataStruct']['data'][0][0].shape[1] ])\n",
    "\n",
    "    for sample in xrange(len(X)):\n",
    "        activity[sample, :] = numpy.var(X[sample]['dataStruct']['data'][0][0], axis=0)\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save feature\n",
    "# feature must be numpy array\n",
    "\n",
    "def save_feature(save_path, data_name, feature_name, feature):\n",
    "        full_save_path = save_path %(data_name, feature_name)\n",
    "        numpy.save(full_save_path, feature)\n",
    "        \n",
    "        print('saved file: ' + str(data_name) + '' + str(feature_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_array = ['F:/Kaggle/Seizure Prediction/train_1/*.mat',\n",
    "             'F:/Kaggle/Seizure Prediction/train_2/*.mat',\n",
    "             'F:/Kaggle/Seizure Prediction/train_3/*.mat',\n",
    "             'F:/Kaggle/Seizure Prediction/test_1/*.mat',\n",
    "             'F:/Kaggle/Seizure Prediction/test_2/*.mat',\n",
    "             'F:/Kaggle/Seizure Prediction/test_3/*.mat']\n",
    "\n",
    "feature_array = ['activity', 'mobility', 'complexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in (path_array):\n",
    "    \n",
    "    \n",
    "    X, Y = load_patient_data(path)\n",
    "    \n",
    "    # remove zero-data from training set\n",
    "    if \"train\" in path:\n",
    "        X, Y = remove_zero_data(X, Y)\n",
    "    \n",
    "    \n",
    "    #compute Hjorth Activty\n",
    "    activity = hjorth_activity(X)\n",
    "    \n",
    "    \n",
    "    #compute Hjorth Parameters in batches\n",
    "\n",
    "    bins = 10\n",
    "    X_len = len(X)\n",
    "    channels = 16\n",
    "\n",
    "\n",
    "    # create list (1 to 1300)\n",
    "    X_index = numpy.linspace(0, X_len-1, X_len-1)\n",
    "    # Separate created list into 10 bins. The size of these bins is used to perform batch computation of FFT\n",
    "    # and half-power frequency calulation\n",
    "    # Calculation is far from optimized\n",
    "    data_bins = numpy.histogram(X_index, bins=bins)\n",
    "    index = 0\n",
    "\n",
    "    mobility = numpy.zeros([len(X), \n",
    "                                X[0]['dataStruct']['data'][0][0].shape[1] ])\n",
    "\n",
    "    complexity = numpy.zeros([len(X), \n",
    "                                X[0]['dataStruct']['data'][0][0].shape[1] ])\n",
    "\n",
    "    \n",
    "    for bin in xrange(bins):\n",
    "        start = time.time()\n",
    "        print('batch number: %s' %(bin))\n",
    "\n",
    "        X_batch = create_X_batch(X, data_bins[0][bin], index)\n",
    "\n",
    "        mobility_batch = hjorth_mobility(X_batch)\n",
    "        mobility[index:index + data_bins[0][bin], :] = mobility_batch\n",
    "\n",
    "        complexity_batch = hjorth_complexity(X_batch)\n",
    "        complexity[index:index + data_bins[0][bin], :] = mobility_batch\n",
    "\n",
    "        index = index + data_bins[0][bin]\n",
    "\n",
    "        print('time elapsed: %s sec' %(time.time() - start))\n",
    "\n",
    "\n",
    "    # save features\n",
    "    data_name = os.path.split(path)[0]\n",
    "    data_name = os.path.split(data_name)[1]\n",
    "    for feature_name in feature_array:\n",
    "        save_feature(save_path = 'F:/Kaggle/Seizure Prediction/features/FEATURE_%s_%s',\n",
    "                    data_name = data_name,\n",
    "                    feature_name = feature_name,\n",
    "                    feature = eval(feature_name))\n",
    "    \n",
    "    #delete data set to clear room for next data set\n",
    "    del X[:]\n",
    "    \n",
    "        \n",
    "    print('')\n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
